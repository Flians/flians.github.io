@inproceedings{DAC25_SeDA,
  author    = {Xuan, Wei and Wang, Zhongrui and Feng, Lang and Lin, Ning and Xuan, Zihao and Fu, Rongliang and Ho, Tsung-Yi and Jiao, Yuzhong and Liang, Luhong},
  booktitle = {Proceedings of the 62nd Design Automation Conference (DAC)},
  numpages  = {6},
  title     = {{SeDA}: Secure and Efficient {DNN} Accelerators with Hardware/Software Synergy},
  year      = {2025}
}

@inproceedings{xuan2025seda,
  author    = {Xuan, Wei and Wang, Zhongrui and Feng, Lang and Lin, Ning and Xuan, Zihao and Fu, Rongliang and Ho, Tsung-Yi and Jiao, Yuzhong and Liang, Luhong},
  booktitle = {Proceedings of the 62nd Design Automation Conference (DAC)},
  title     = {{SeDA}: Secure and Efficient {DNN} Accelerators with Hardware/Software Synergy},
  year      = {2025},
  volume    = {},
  number    = {},
  pages     = {1-7},
  abstract  = {Ensuring the confidentiality and integrity of DNN accelerators is paramount across various scenarios spanning autonomous driving, healthcare, and finance. However, current security approaches typically require extensive hardware resources, and incur significant off-chip memory access overheads. This paper introduces SeDA, which utilizes 1) a bandwidth-aware encryption mechanism to improve hardware resource efficiency, 2) optimal block granularity through intra-layer and inter-layer tiling patterns, and 3) a multi-level integrity verification mechanism that minimizes, or even eliminates, memory access overheads. Experimental results show that SeDA decreases performance overhead by over 12% for both server and edge neural processing units (NPUs), while ensuring robust scalability.11SeDA source code:https://github.com/wayne4s/seda.git},
  keywords  = {Source coding;Scalability;Memory management;Artificial neural networks;Bandwidth;Hardware;Encryption;Servers;Security;Protection;Memory protection;secure DNN accelerators;confidentiality and integrity;deep neural networks},
  doi       = {10.1109/DAC63849.2025.11133180}
}
